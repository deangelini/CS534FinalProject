# -*- coding: utf-8 -*-
"""pytorchFruitCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14rjJC6YDkhTulVunQVb1HUyC2MCHmn_c

# Init Google Colab
"""

# Commented out IPython magic to ensure Python compatibility.
import os
from google.colab import drive
drive.mount('/content/gdrive/')

# %cd /content/gdrive/MyDrive/AI_class

#!pip install bayesian-optimization
!pip install optuna

"""# Library"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import torch 
from torch.utils.data.dataset import Dataset
from torch.utils.data.sampler import SubsetRandomSampler
from torch.utils.data import DataLoader
import glob
import cv2
import torchvision.transforms as transforms
from tqdm import tqdm_notebook
import torch.nn.functional as F
import torch.optim as optim
import torch.nn as nn

from sklearn.model_selection import cross_val_score
from keras.models import Sequential
from keras.layers import Dense, BatchNormalization, Dropout
from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl
from keras.callbacks import EarlyStopping, ModelCheckpoint
#from bayes_opt import BayesianOptimization
from keras.layers import LeakyReLU
LeakyReLU = LeakyReLU(alpha=0.1)

import tensorflow as tf
import torch
import keras
import optuna
import torchvision.transforms as transforms
from torch.utils.data.dataset import Dataset
from torch.utils.data.sampler import SubsetRandomSampler
from torch.utils.data import DataLoader
import torch.nn.functional as F
import torch.optim as optim
import torch.nn as nn
import cv2
import glob
import numpy as np
import random
import matplotlib.pyplot as plt
import datetime
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

"""# Data Preprocessing"""

training_dir = '/content/gdrive/MyDrive/AI_class/dataset/train'
testing_dir = '/content/gdrive/MyDrive/AI_class/dataset/test'


def get_image(path,transform=False):
    img = cv2.imread(path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    if transform:
        img = transform(img)
    return img

def show_data(rows,cols,is_train=True,transform=False):
    if is_train:path = training_dir
    else:path = testing_dir
    path = os.path.join(path,'*','*','*.png')
    img_paths = glob.glob(path)
    np.random.seed(0)
    img_paths = np.random.choice(img_paths,rows*cols)
    fig = plt.figure(figsize=(8,8),dpi=150)
    i = 1
    for r in range(rows):
        for c in range(cols):
            image_path = img_paths[i-1]
            if 'fresh' in image_path.split('/')[-2]:
                title = 'Fresh'
            else:
                title = 'Rotten'
            ax = fig.add_subplot(rows,cols,i)
            img = get_image(image_path,transform)
            ax.set_xticks([])
            ax.set_yticks([])
            ax.set_title(title,fontsize=5)
            ax.imshow(img)
            i+=1
    return fig

class FruitsDataset(Dataset):
    def __init__(self,path,classifier_type='Rotten',subset='train',transforms=None, fruit_type=''):
        self.subset = subset
        self.fruit_type = fruit_type
        dir_val = '*'
        if self.fruit_type != '':
          dir_val = self.subset + '_' + self.fruit_type

        if self.subset == 'train':
            self.PATH = os.path.join(path,'train',dir_val,'*','*.png')
        elif self.subset == 'test':
            self.PATH = os.path.join(path,'test',dir_val,'*','*.png')
        self.data = glob.glob(self.PATH)
        self.height = 32
        self.width = 32
        self.labels = [] 
        if classifier_type == 'Rotten':
            classes = ['fresh','rotten']
            for fruit in self.data:
                if classes[0] in fruit.split('/')[-2]:
                    self.labels.append(0)
                else:
                    self.labels.append(1)
        else:
            classes = ['apple','banana','orange']
            for fruit in self.data:
                if classes[0] in fruit:
                    self.labels.append(0)
                elif classes[1] in fruit:
                    self.labels.append(1)
                else:
                    self.labels.append(2)
        self.transforms = transforms
      
    def __getitem__(self,index):
        img_path = self.data[index]
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
        img = cv2.resize(img,(self.width,self.height))
        label = self.labels[index]
        if self.transforms is not None:
            img_as_tensor = self.transforms(img)
            if self.transforms is not None:
                return(img_as_tensor,label)
            return(img,label)
  
    def __len__(self):
        return(len(self.data))

fig = show_data(5,4, is_train = True)
fig.tight_layout()

"""## Transformation"""

#Change type here
t1 = (0.5,0.5,0.5)
t2 = (0.5,0.5,0.5)
transformations = transforms.Compose([
                                      transforms.ToTensor(),
                                      transforms.Normalize(t1,t2)
                                      ])
dataset = FruitsDataset('/content/gdrive/MyDrive/AI_class/dataset',transforms = transformations, fruit_type="")
img_t, _ = dataset[1000]
img = img_t.permute(1,2,0)
plt.imshow(img);

"""# Model"""

batch_size = 32
validation_split = .2
shuffle_dataset = True
random_seed= 42
# Creating data indices for training and validation splits:
dataset_size = len(dataset)
#for hyperparameter tuning 
#dataset_size = round(len(dataset) * 0.5) 
indices = list(range(dataset_size))
split = int(np.floor(validation_split * dataset_size))
if shuffle_dataset :
    np.random.seed(random_seed)
    np.random.shuffle(indices)
# train_indices, val_indices = indices[0:100], indices[101:150]
val_indices, train_indices = indices[0:split], indices[split+1:-1]
print("Test size: ", split)
print("Train size: ", dataset_size - split)


# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
test_sampler = SubsetRandomSampler(val_indices)

train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, 
                                           sampler=train_sampler, num_workers = 2, pin_memory=True)
test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,
                                                sampler=test_sampler, num_workers = 2, pin_memory=True)

class AlexNet(nn.Module):
    def __init__(self, num_classes=1000):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=1, stride=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(64, 192, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(192, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x


# net = AlexNet()
# criterion = nn.CrossEntropyLoss()
# optimizer = optim.SGD(net.parameters(), lr=0.0000001, momentum=0.9, weight_decay=0.001)

model = AlexNet()
numel_list = [p.numel() for p in model.parameters()]
sum(numel_list), numel_list

device = (torch.device('cuda') if torch.cuda.is_available()
  else torch.device('cpu'))
print(f"Training on device {device}.")

train_losses = []
valid_losses = []

def training_loop(n_epochs,optimizer,model,loss_fn,train_loader):
    for epoch in tqdm_notebook(range(1,n_epochs+1)):
        train_loss = 0.0
        valid_loss = 0.0
        for imgs, labels in train_loader:
            imgs = imgs.to(device=device)
            labels = labels.to(device=device)
            outputs = model(imgs)
            loss = loss_fn(outputs,labels)
            #get rid of gradients from last round
            optimizer.zero_grad()
            #performs backward step. Computes all the gradients
            loss.backward()
            #Updates the model
            optimizer.step()
            train_loss += loss.item()
        train_loss /= len(train_loader.dataset)
        train_losses.append(train_loss)

        with torch.no_grad():
          for imgs, labels in test_loader:
              outputs = model(imgs.cuda())
              loss = loss_fn(outputs, labels.cuda())
              valid_loss += loss.item()# * imgs.size(0)
          valid_loss /= len(test_loader.dataset)
          valid_losses.append(valid_loss)
        
        print(f'{datetime.datetime.now()}, 'f'Epoch: {epoch}/{n_epochs}, '
          f'Training Loss: {train_loss:.4f}, '
          f'Validation Loss: {valid_loss:.4f}')
        
def hyperparameter_training_loop(params_nn,model,loss_fn,train_loader):
    n_epochs = params_nn['epochs']
    for epoch in tqdm_notebook(range(1,n_epochs+1)):
        train_loss = 0.0
        valid_loss = 0.0
        optimizer = getattr(optim, params_nn['optimizer'])(model.parameters(), lr= params_nn['learning_rate'])
        for imgs, labels in train_loader:
            imgs = imgs.to(device=device)
            labels = labels.to(device=device)
            outputs = model(imgs)
            loss = loss_fn(outputs,labels)
            #get rid of gradients from last round
            optimizer.zero_grad()
            #performs backward step. Computes all the gradients
            loss.backward()
            #Updates the model
            optimizer.step()
            train_loss += loss.item()
        train_loss /= len(train_loader.dataset)
        train_losses.append(train_loss)

        with torch.no_grad():
          for imgs, labels in test_loader:
              outputs = model(imgs.cuda())
              loss = loss_fn(outputs, labels.cuda())
              valid_loss += loss.item()# * imgs.size(0)
          valid_loss /= len(test_loader.dataset)
          valid_losses.append(valid_loss)
        
        return valid_loss

        # print('{} Epoch {}, Training Loop {}'.format(
        #   datetime.datetime.now(), epoch, train_loss/len(train_loader)))

"""# Hyperparameter Tuning"""

# Create function
def objective(trial):
  params_nn = {
      'optimizer': trial.suggest_categorical('optimizer',['SGD', 'Adam', 'RMSprop', 'Adadelta', 
                                                           'Adagrad', 'Adamax']),
      'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),
      'activation': trial.suggest_categorical('activation',['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',
                   'elu', 'exponential', LeakyReLU]),
      'epochs': trial.suggest_int('epochs', 20, 100)
  }
  model = AlexNet().to(device=device)
  loss_fn = nn.CrossEntropyLoss()
  valid_loss = hyperparameter_training_loop(params_nn = params_nn,
      model = model,
      loss_fn = loss_fn,
      train_loader = train_loader,
)
  return valid_loss

TRIALS = 50
    
study = optuna.create_study(direction="minimize", sampler=optuna.samplers.TPESampler())
study.optimize(objective, n_trials=TRIALS)

#Choosing Best Parameters
best_trial = study.best_trial

for key, value in best_trial.params.items():
    print("{}: {}".format(key, value))

"""# Model Results"""

#optimizer = Adamax
learning_rate = 0.0013122150094010906
#activation = softplus
epochs = 26

model = AlexNet().to(device=device) #was talking about this above
optimizer = optim.Adamax(model.parameters(), lr=learning_rate)
#optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.001)
loss_fn = nn.CrossEntropyLoss()
training_loop(
  n_epochs = epochs,
  optimizer = optimizer,
  model = model,
  loss_fn = loss_fn,
  train_loader = train_loader,
)

plt.plot(train_losses, label='Training')
plt.plot(valid_losses, label='Validation')
plt.legend(frameon=False)
plt.title("Training And Validation Loss")
plt.xlabel('Epochs')
plt.show()

def validate(model,train_loader,val_loader):
    for name, loader in [('train',train_loader),('val',test_loader)]:
        correct = 0
        total = 0

        #gradients nor required, as we don't want to train our parameters
        with torch.no_grad():
            for imgs, labels in loader:
                imgs = imgs.to(device=device)
                labels = labels.to(device=device)
                outputs = model(imgs)
                #max_index,value
                _,predicted = torch.max(outputs,dim=1)
                total+=labels.shape[0]
                correct+=int((predicted==labels).sum())
    
        print('Accuracy {}: {:.4f}'.format(name, correct/total))

validate(model,train_loader,test_loader)